<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Shengjun Zhang</title>
  
  <meta name="author" content="Shengjun Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6EJMX75K3R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6EJMX75K3R');
</script>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shengjun Zhang</name>
              </p>
              <p>I am a Ph.D student in the Department of Electronic Engineering at Tsinghua University, advised by 
                Prof. <a href="https://duanyueqi.github.io/">Yueqi Duan</a>. Before that, I obtained my B.Eng. in the 
                Department of Engineering Physics, Tsinghua University. My research interest lie in 3D computer vision and world model.
                Feel free to contact me if you are interested in our works or would like to work with us.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhangsj2020@foxmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.cz/citations?user=wsmc4XcAAAAJ&hl=cs&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shengjun-zhang">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/icon.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/icon.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                <b>2024-09:</b> One paper on object-goal navigation is accepted to <a href="https://nips.cc/">NeurIPS 2024</a>.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table> -->
          
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Physics3D.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion</papertitle>
              <br>
              Fangfu Liu*,
              Hanyang Wang*,
              Shunyu Yao,
              <strong>Shengjun Zhang</strong>,
              Jie Zhou,
              Yueqi Duan
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2406.04338">[arXiv]</a>
              <a href="https://github.com/liuff19/Physics3D">[Code]</a>
              <a href="https://liuff19.github.io/Physics3D">[Project Page]</a> 
              <br>
              <p> In this paper, we propose Physics3D, a novel method for learning various physical properties of 3D objects through a video diffusion model. Our approach involves designing a highly generalizable physical simulation system based on a viscoelastic material model, which enables us to simulate a wide range of materials with high-fidelity capabilities. </p>
            </td>
          </tr>
        </tbody></table>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                *Equal contribution &nbsp;&nbsp; <sup>â€ </sup>Project leader
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/SurfelSplat.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SurfelSplat: Learning Efficient and Generalizable Gaussian Surfel Representations for Sparse-View Surface Reconstruction</papertitle>
              <br>
              Chensheng Dai*,
              <strong>Shengjun Zhang*</strong>, 
              Min Chen,
              Yueqi Duan
              <br>
              <em>Thirty-ninth Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2025
              <br>
              <!-- <a href="https://arxiv.org/abs/2507.18758">[arXiv]</a> -->
              <!-- <a href="https://github.com/shengjun-zhang/Scene-Splatter">[Code]</a> -->
              <!-- <a href="https://simon-dcs.github.io/Human_Gaussian_Graph/">[Project Page]</a> -->
              <!-- <br>
              <a href="https://arxiv.org/">[arXiv]</a> <a href="https://github.com/bagh2178/SG-Nav">[Code]</a> <a href="https://bagh2178.github.io/SG-Nav/">[Project Page]</a>
              <br> -->
              <p> We propose SurfaceSplat, a feed-forward framework that generates efficient and generalizable pixel-aligned 
                Gaussian surfel representations from sparse-view images. We observe that conventional feed-forward structures struggle 
                to recover accurate geometric attributes of Gaussian surfels because the spatial frequency of pixel-aligned primitives 
                exceeds Nyquist sampling rates.  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/HGG.bmp' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Efficient and Generalizable Human Representation with Human Gaussian Model</papertitle>
              <br>
              Yifan Liu*,
              <strong>Shengjun Zhang*</strong>, 
              Chensheng Dai,
              Yang Chen, 
              Hao Liu,
              Chen Li,
              Yueqi Duan
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2507.18758">[arXiv]</a>
              <!-- <a href="https://github.com/shengjun-zhang/Scene-Splatter">[Code]</a> -->
              <a href="https://simon-dcs.github.io/Human_Gaussian_Graph/">[Project Page]</a>
              <!-- <br>
              <a href="https://arxiv.org/">[arXiv]</a> <a href="https://github.com/bagh2178/SG-Nav">[Code]</a> <a href="https://bagh2178.github.io/SG-Nav/">[Project Page]</a>
              <br> -->
              <p>  In this paper, we propose Human Gaussian Graph (HGG) to generate generalizable and animatable Gaussian representations. 
                We leverage the human structure prior to recover generalizable and animatable Gaussian representations  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ScenePainter.bmp' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>ScenePainter: Semantically Consistent Perpetual 3D Scene Generation with Concept Relation Alignment</papertitle>
              <br>
              Chong Xia,
              <strong>Shengjun Zhang</strong>, 
              Fangfu Liu,
              Chang Liu, 
              Khodchaphun Hirunyaratsameewong,
              Yueqi Duan
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2507.19058">[arXiv]</a>
              <a href="https://github.com/xiac20/ScenePainter">[Code]</a>
              <a href="https://xiac20.github.io/ScenePainter/">[Project Page]</a>
              <!-- <br>
              <a href="https://arxiv.org/">[arXiv]</a> <a href="https://github.com/bagh2178/SG-Nav">[Code]</a> <a href="https://bagh2178.github.io/SG-Nav/">[Project Page]</a>
              <br> -->
              <p>  In this paper, we propose ScenePainter, a new framework for semantically consistent 3D scene generation, 
                which aligns the outpainter's scene-specific prior with the comprehension of the current scene. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/SceneSplatter.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model</papertitle>
              <br>
              <strong>Shengjun Zhang</strong>, 
              Jinzhao Li,
              Xin Fei, 
              Hao Liu,
              Yueqi Duan
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2504.02764">[arXiv]</a>
              <a href="https://github.com/shengjun-zhang/Scene-Splatter">[Code]</a>
              <a href="https://shengjun-zhang.github.io/SceneSplatter">[Project Page]</a>
              <!-- <br>
              <a href="https://arxiv.org/">[arXiv]</a> <a href="https://github.com/bagh2178/SG-Nav">[Code]</a> <a href="https://bagh2178.github.io/SG-Nav/">[Project Page]</a>
              <br> -->
              <p> In this paper, we propose Scene Splatter, a momentum 3D scene generation paradigm to introduce existing scene information as momentum in the generation process, 
                to balance the generative prior and scene consistency.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/GGN.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Gaussian Graph Network: Learning Efficient and Generalizable Gaussian Representations from Multi-view Images </papertitle>
              <br>
              <strong>Shengjun Zhang</strong>, 
              Xin Fei, 
              Fangfu Liu, 
              HaiXu Song,
              Yueqi Duan
              <br>
              <em>Thirty-eighth Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2503.16338">[arXiv]</a>
              <a href="https://github.com/shengjun-zhang/GGN">[Code]</a>
              <a href="https://shengjun-zhang.github.io/GGN">[Project Page]</a>
              <!-- <br>
              <a href="https://arxiv.org/">[arXiv]</a> <a href="https://github.com/bagh2178/SG-Nav">[Code]</a> <a href="https://bagh2178.github.io/SG-Nav/">[Project Page]</a>
              <br> -->
              <p> In this paper, we propose Gaussian Graph Network (GGN) to generate efficient and generalizable Gaussian representations.</p>
            </td>
          </tr>

          

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GeoAuxNet.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GeoAuxNet: Towards Universal 3D Representation Learning for Multi-sensor Point Clouds</papertitle>
              <br>
              <strong>Shengjun Zhang</strong>, 
              Xin Fei, 
              Yueqi Duan
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2403.19220">[arXiv]</a>
              <a href="https://github.com/shengjun-zhang/GeoAuxNet">[Code]</a>
              <br>
              <p> In
                this paper, we propose geometry-to-voxel auxiliary learning to enable voxel representations to access point-level geometric information, which supports better generalisation of the voxel-based backbone with additional interpretations of multi-sensor point clouds. </p>
            </td>
          </tr>

       

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>              
                <li style="margin: 5px;"> National Scholarship, 2020, 2021, 2022</li>
                <li style="margin: 5px;"> Outstanding Graduates, Beijing, 2023</li>
                <li style="margin: 5px;"> Jining Yingcai Scholarship, Tsinghua, 2024</li>
                <li style="margin: 5px;"> Outstanding Graduates, Tsinghua, 2023</li>
                <li style="margin: 5px;"> Ye Qisun Scholarship, Tsinghua, 2023</li>
                <li style="margin: 5px;"> Outstanding Student Cadre, Tsinghua, 2022</li> 
                <li style="margin: 5px;"> Outstanding CLP member, Tsinghua, 2020</li>
                <li style="margin: 5px;"> Chinese Mathematical Olympiad, Silver Medal, 2017</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                Review for <b>TMM</b>, <b>CVPR</b>, <b>ICCV</b>, <b>NeurIPS</b>, <b>ICLR</b>, <b>ICME</b>.
              </li>
          </td>
        </tr>
      </tbody></table>
       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>      
    <br>
      &copy; Shengjun Zhang | Last update: Jun. 26, 2025
</center></p>
</body>

</html>