<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
    .title.is-3 {
      text-align: center;
    }

    .image-container {
      width: 80%;
      margin: 0 auto;
    }

    .image-container img {
      display: block;
      width: 100%;
      height: auto;
      border: 1px solid #ddd;
      border-radius: 8px;
    }

    .has-text-left {
      text-align: justify;
      font-size: 18px;
      color: #555;
    }
    .image img {
      width: 80%;
      margin: 0 auto;
    }
    .video-container {
      display: flex;
      justify-content: center;
    }

  </style>


  <title>Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  

</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://shengjun-zhang.github.io/" target="_blank">Shengjun Zhang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Jinzhao Li</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/Barrybarry-Smith/" target="_blank">Xin Fei</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Hao Liu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://duanyueqi.github.io/" target="_blank">Yueqi Duan</a><sup>1,&#10013</sup>
              </span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University, <sup>2</sup>Tecent</span>
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.02764" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
  
              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span> -->
  
            <!-- Github link -->
            <span class="link-block">
              <a href="https://github.com/YOUR REPO HERE" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
            </span>
  
            <!-- ArXiv abstract Link -->
            <!-- <span class="link-block">
              <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="ai ai-arxiv"></i>
              </span>
              <span>arXiv</span>
            </a>
          </span> -->
        </div>
      </div>
    </div>
  </section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="video-container">
        <video poster="" id="tree" autoplay controls muted loop>
          <source src="static\videos\output_video2.mp4" type="video/mp4">
        </video>
      </div>
      <h2 class="subtitle has-text-centered" style="font-size: 16px;">
        Scene Splatter, a momentum-based paradigm for video diffusion to generate generic scenes from single image.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, we propose Scene Splatter, a momentum-based paradigm for video diffusion to generate generic scenes from single image. Existing methods, which employ video generation models to synthesize novel views, suffer from limited video length and scene inconsistency, leading to artifacts and distortions during further reconstruction. To address this issue, we construct noisy samples from original features as momentum to enhance video details and maintain scene consistency. However, for latent features with the perception field that spans both known and unknown regions, such latent-level momentum restricts the generative ability of video diffusion in unknown regions. Therefore, we further introduce the aforementioned consistent video as a pixel-level momentum to a directly generated video without momentum for better recovery of unseen regions. Our cascaded momentum enables video diffusion models to generate both high-fidelity and consistent novel views. We further finetune the global Gaussian representations with enhanced frames and render new frames for momentum update in the next step. In this manner, we can iteratively recover a 3D scene, avoiding the limitation of video length. Extensive experiments demonstrate the generalization capability and superior performance of our method in high-fidelity and consistent scene generation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->







<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h2 class="title is-3">Rendering results of a single-view reconstruction scene</h2>
      <div id="results-carousel" class="carousel results-carousel is-centered">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop width="80%">
            <source src="static\videos\output_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop width="80%">
            <source src="static\videos\output_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop width="80%">
            <source src="static\videos\output_1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>






<section class="hero is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h2 class="title is-3">Results of our method on more camera trajectories</h2>
      <div class="image">
        <img src="static/images/trajectory.png" alt="MY ALT TEXT" style="width: 80%; height: auto; border: 1px solid #ddd; border-radius: 8px;" />
      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h2 class="title is-3">Results of our method compared with baselines</h2>
      <div class="image">
        <img src="static\images\teaser.png" alt="MY ALT TEXT" style="width: 80%; height: auto; border: 1px solid #ddd; border-radius: 8px;" />
      </div>
    </div>
  </div>
</section>



<section class="hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Method Overview</h2>
      <div class="image-container">
        <img src="static/images/pipeline.png" alt="MY ALT TEXT" />
        <p class="has-text-left" style="margin-top: 10px;">
          The pipeline of Scene Splatter. We initialize the Gaussian representations from the input image \(I_{0}\) with a Gaussian Predictor. For each iteration, we first render the video \(\mathcal{I}\) from 3D Gaussians \(\mathcal{G}\). Then, we generate the enhanced video \(\Phi_{\lambda}(\mathcal{I})\) with latent-level momentum and \(\Phi_{0}(\mathcal{I})\) directly from the vanilla diffusion model, where \(\Phi_{\lambda}\) and \(\Phi_{0}\) share the same weights of the denoising network. We further render scale maps as pixel-level momentum coefficient to further enhance the generated frames. We use the final results to supervise the optimization of Gaussian representations. We conduct this process along the camera trajectory to iteratively recover 3D scenes.
        </p>
      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@article{Scene Splatter,
        title   = {Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model},
        author  = {Zhang, Shengjun and Li, Jinzhao and Fei, Xin and Liu, Hao and Duan, Yueqi},
        journal = {IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)},
        year    = {2025},
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  </body>
  </html>
